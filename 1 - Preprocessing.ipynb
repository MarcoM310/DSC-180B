{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AiDA Lab Tutorial Part 7a--Transfer Learning  Preprocessing (Special Thanks to Dr. Kyle Hasenstab)\n",
    "\n",
    "By now, you should have trained a simple CNN to accomplish the super-resolution task with either a 955 (part 5) or UNet (part 6).  As you have seen, while results are good, it can take a long time to train these models depending on the complexity of the task.  What if instead, you can for example, take a CNN trained to identify soccer balls in an image, and \"transfer\" its knowledge to a new task to identify basketballs in an image?  This is the core of the concept of transfer learning.  Transfer learning essentially entails training a model to perform one task, saving the model parameters and weights, then loading those saved weights as an initial starting point when training either the same or modified CNN for a different task!  https://www.tensorflow.org/tutorials/images/transfer_learning is a good reference\n",
    "\n",
    "Here, we will use the model developed by Dr. Kang Wang, one of the stellar T32 Residents who worked for Albert in around 2018.  His paper is located here and in the repo (Kang_Radiology_AI_Paper): https://pubs.rsna.org/doi/full/10.1148/ryai.2019180022\n",
    "\n",
    "As you are now acquianted with coding in python, I will preface the CNN training with pseudo-code you will need done in pre-training, as this will differ based on your specific task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Pseudo-Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import traceback\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in all hdf5 files\n",
    "WORKING_DIR = os.getcwd()\n",
    "\n",
    "HDF_PATH = \"C:/Users/david/Desktop/DSC 180A - FA22/Code/data/\"\n",
    "if not os.path.exists(HDF_PATH):\n",
    "    print(\"HDF_PATH does not exist. Please change the path to the data folder.\")\n",
    "\n",
    "SAVE_PATH = os.path.join(WORKING_DIR,\"data\")\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)\n",
    "if not os.path.exists(os.path.join(SAVE_PATH,\"1024_images\")):\n",
    "    os.mkdir(os.path.join(SAVE_PATH,\"1024_images\"))\n",
    "if not os.path.exists(os.path.join(SAVE_PATH,\"256_images\")):\n",
    "    os.mkdir(os.path.join(SAVE_PATH,\"256_images\"))\n",
    "\n",
    "file0 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_0.hdf5\", 'r')\n",
    "file1 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_1.hdf5\", 'r')\n",
    "file2 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_2.hdf5\", 'r')\n",
    "file3 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_3.hdf5\", 'r')\n",
    "file4 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_4.hdf5\", 'r')\n",
    "file5 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_5.hdf5\", 'r')\n",
    "file6 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_6.hdf5\", 'r')\n",
    "#file7 = h5py.File(\"bnpp_frontalonly_1024_7.hdf5\", 'r')\n",
    "file10 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_10.hdf5\", 'r')\n",
    "\n",
    "files = [file0, file1, file2, file3, file4, file5, file6, file10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving all images to 1024_images folder\n",
    "# i = 0\n",
    "# for file in files:\n",
    "#     for key in file.keys():\n",
    "#         im = np.asarray(file[key])\n",
    "#         if not os.path.exists(os.path.join(SAVE_PATH,'1024_images',str(key),'.png')):\n",
    "#             plt.imsave(SAVE_PATH + '/1024_images/' + key + '.png', arr = im, cmap = 'gray')\n",
    "#         i += 1\n",
    "#         if i % 500 == 0:\n",
    "#             print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('# of 1024 Images: ',len([name for name in os.listdir(os.getcwd()+'/data/1024_images') if os.path.isfile(os.path.join(os.getcwd()+'/data/1024_images', name))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving all images to 256_images folder\n",
    "# i=0\n",
    "# for file in files:\n",
    "#     for key in file.keys():\n",
    "#         im = Image.open(SAVE_PATH + '/1024_images/' + key + '.png')\n",
    "#         #print(im.size)\n",
    "#         im = im.resize((256,256))\n",
    "#         #print(im.size)\n",
    "#         if not os.path.exists(os.path.join(SAVE_PATH, '/256_images/', key, '.png')):\n",
    "#             im.save(SAVE_PATH + '/256_images/' + key + '.png')\n",
    "#         i += 1\n",
    "#         if i % 500 == 0:\n",
    "#             print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key            object\n",
       "age_at_sampletime    float64\n",
       "bmi                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(WORKING_DIR+'\\\\BNPP_data_frontalonly_AgesBMI_06242021_dsc180.csv')\n",
    "df1.drop(columns=['phonetic_id','Sample_Collection_TM'], inplace=True)\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key         object\n",
       "bnpp_value_num    float64\n",
       "cr_value_num      float64\n",
       "Has_PNA             int64\n",
       "Has_AcuteHF         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(WORKING_DIR+'\\\\BNPPlabs_dcmlist_merged_noMRN_frontal_only_dsc180a.csv')\n",
    "df2.drop(columns=['phonetic_id','unique_key.1','ref_unit','cr_unit','bnpp_value'], inplace=True)\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_at_sampletime    float64\n",
      "bmi                  float64\n",
      "bnpp_value_num       float64\n",
      "cr_value_num         float64\n",
      "Has_PNA                int64\n",
      "Has_AcuteHF            int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_at_sampletime</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bnpp_value_num</th>\n",
       "      <th>cr_value_num</th>\n",
       "      <th>Has_PNA</th>\n",
       "      <th>Has_AcuteHF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abachug_50267230_img1</th>\n",
       "      <td>59.0</td>\n",
       "      <td>25.51</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abadik_50217497_img1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>31.38</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abafouck_52403307_img1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>33.81</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abagash_52691625_img1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.64</td>\n",
       "      <td>49.9</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abakleem_50725934_img1</th>\n",
       "      <td>59.0</td>\n",
       "      <td>34.81</td>\n",
       "      <td>20029.0</td>\n",
       "      <td>10.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zufosloo_50189474_img1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>44.06</td>\n",
       "      <td>2988.0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuliquep_52986445_img1</th>\n",
       "      <td>68.0</td>\n",
       "      <td>26.07</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zunakot_51932665_img1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuplouke_51797661_img1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>27.66</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuridi_50548513_img1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>32.81</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23536 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        age_at_sampletime    bmi  bnpp_value_num  \\\n",
       "unique_key                                                         \n",
       "Abachug_50267230_img1                59.0  25.51           418.0   \n",
       "Abadik_50217497_img1                 58.0  31.38          2161.0   \n",
       "Abafouck_52403307_img1               58.0  33.81           118.0   \n",
       "Abagash_52691625_img1                60.0  30.64            49.9   \n",
       "Abakleem_50725934_img1               59.0  34.81         20029.0   \n",
       "...                                   ...    ...             ...   \n",
       "Zufosloo_50189474_img1               54.0  44.06          2988.0   \n",
       "Zuliquep_52986445_img1               68.0  26.07          5684.0   \n",
       "Zunakot_51932665_img1                62.0  22.73           123.0   \n",
       "Zuplouke_51797661_img1               85.0  27.66          1290.0   \n",
       "Zuridi_50548513_img1                 46.0  32.81          1542.0   \n",
       "\n",
       "                        cr_value_num  Has_PNA  Has_AcuteHF  \n",
       "unique_key                                                  \n",
       "Abachug_50267230_img1           0.61        1            0  \n",
       "Abadik_50217497_img1            1.31        0            0  \n",
       "Abafouck_52403307_img1          0.66        0            0  \n",
       "Abagash_52691625_img1           0.64        0            0  \n",
       "Abakleem_50725934_img1         10.54        0            0  \n",
       "...                              ...      ...          ...  \n",
       "Zufosloo_50189474_img1          1.29        0            1  \n",
       "Zuliquep_52986445_img1          0.50        0            1  \n",
       "Zunakot_51932665_img1           0.94        0            0  \n",
       "Zuplouke_51797661_img1          1.77        0            0  \n",
       "Zuridi_50548513_img1            1.11        0            1  \n",
       "\n",
       "[23536 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(df1, df2, on='unique_key', how='inner')\n",
    "data.index = data['unique_key']\n",
    "data.drop(columns=['unique_key'], inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "print(data.dtypes)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:18<00:00,  9.75s/it]\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "ids = []\n",
    "bnpp = []\n",
    "no_values = []\n",
    "cardio_edema = []\n",
    "other = []\n",
    "for file in tqdm(files):\n",
    "    for key in file.keys():\n",
    "        im = Image.open(SAVE_PATH + '/256_images/' + key + '.png')\n",
    "        im = np.asarray(im)\n",
    "        im = (im - np.min(im))/(np.max(im) - np.min(im))\n",
    "        try:\n",
    "            row = data.loc[key].values\n",
    "            bnpp.append(row[2])\n",
    "            if row[2] >= 400:\n",
    "                cardio_edema.append(1)\n",
    "            else:\n",
    "                cardio_edema.append(0)\n",
    "            d = np.array([row[0], row[1], row[3], row[4], row[5]], dtype='object')\n",
    "            other.append(d)\n",
    "        except:\n",
    "            no_values.append(key)\n",
    "            continue\n",
    "        images.append(im)\n",
    "        ids.append(key)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Non-null images:  16567\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 32.4 GiB for an array with shape (16567, 256, 256, 4) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m# Non-null images: \u001b[39m\u001b[39m'\u001b[39m,\u001b[39mlen\u001b[39m(images))\n\u001b[1;32m----> 2\u001b[0m images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(images)\n\u001b[0;32m      3\u001b[0m images[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 32.4 GiB for an array with shape (16567, 256, 256, 4) and data type float64"
     ]
    }
   ],
   "source": [
    "print('# Non-null images: ',len(images))\n",
    "images = np.array(images)\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>cr</th>\n",
       "      <th>Has_PNA</th>\n",
       "      <th>Has_AcuteHF</th>\n",
       "      <th>images</th>\n",
       "      <th>bnpp</th>\n",
       "      <th>cardio_edema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abachug_50267230_img1</th>\n",
       "      <td>59.0</td>\n",
       "      <td>25.51</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[104, 104, 104, 255], [88, 88, 88, 255], [73...</td>\n",
       "      <td>418.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abadik_50217497_img1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>31.38</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[196, 196, 196, 255], [191, 191, 191, 255], ...</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abafouck_52403307_img1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>33.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[41, 41, 41, 255], [32, 32, 32, 255], [27, 2...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abagash_52691625_img1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[5, 5, 5, 255], [4, 4, 4, 255], [4, 4, 4, 25...</td>\n",
       "      <td>49.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abakleem_50725934_img1</th>\n",
       "      <td>59.0</td>\n",
       "      <td>34.81</td>\n",
       "      <td>10.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[22, 22, 22, 255], [16, 16, 16, 255], [13, 1...</td>\n",
       "      <td>20029.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zufosloo_50189474_img1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>44.06</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[1, 1, 1, 255], [0, 0, 0, 255], [3, 3, 3, 25...</td>\n",
       "      <td>2988.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuliquep_52986445_img1</th>\n",
       "      <td>68.0</td>\n",
       "      <td>26.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[0, 0, 0, 255], [0, 0, 0, 255], [0, 0, 0, 25...</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zunakot_51932665_img1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[201, 201, 201, 255], [177, 177, 177, 255], ...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuplouke_51797661_img1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>27.66</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[141, 141, 141, 255], [141, 141, 141, 255], ...</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuridi_50548513_img1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>32.81</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[0, 0, 0, 255], [0, 0, 0, 255], [0, 0, 0, 25...</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16567 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         age    bmi     cr  Has_PNA  Has_AcuteHF  \\\n",
       "Abachug_50267230_img1   59.0  25.51   0.61      1.0          0.0   \n",
       "Abadik_50217497_img1    58.0  31.38   1.31      0.0          0.0   \n",
       "Abafouck_52403307_img1  58.0  33.81   0.66      0.0          0.0   \n",
       "Abagash_52691625_img1   60.0  30.64   0.64      0.0          0.0   \n",
       "Abakleem_50725934_img1  59.0  34.81  10.54      0.0          0.0   \n",
       "...                      ...    ...    ...      ...          ...   \n",
       "Zufosloo_50189474_img1  54.0  44.06   1.29      0.0          1.0   \n",
       "Zuliquep_52986445_img1  68.0  26.07   0.50      0.0          1.0   \n",
       "Zunakot_51932665_img1   62.0  22.73   0.94      0.0          0.0   \n",
       "Zuplouke_51797661_img1  85.0  27.66   1.77      0.0          0.0   \n",
       "Zuridi_50548513_img1    46.0  32.81   1.11      0.0          1.0   \n",
       "\n",
       "                                                                   images  \\\n",
       "Abachug_50267230_img1   [[[104, 104, 104, 255], [88, 88, 88, 255], [73...   \n",
       "Abadik_50217497_img1    [[[196, 196, 196, 255], [191, 191, 191, 255], ...   \n",
       "Abafouck_52403307_img1  [[[41, 41, 41, 255], [32, 32, 32, 255], [27, 2...   \n",
       "Abagash_52691625_img1   [[[5, 5, 5, 255], [4, 4, 4, 255], [4, 4, 4, 25...   \n",
       "Abakleem_50725934_img1  [[[22, 22, 22, 255], [16, 16, 16, 255], [13, 1...   \n",
       "...                                                                   ...   \n",
       "Zufosloo_50189474_img1  [[[1, 1, 1, 255], [0, 0, 0, 255], [3, 3, 3, 25...   \n",
       "Zuliquep_52986445_img1  [[[0, 0, 0, 255], [0, 0, 0, 255], [0, 0, 0, 25...   \n",
       "Zunakot_51932665_img1   [[[201, 201, 201, 255], [177, 177, 177, 255], ...   \n",
       "Zuplouke_51797661_img1  [[[141, 141, 141, 255], [141, 141, 141, 255], ...   \n",
       "Zuridi_50548513_img1    [[[0, 0, 0, 255], [0, 0, 0, 255], [0, 0, 0, 25...   \n",
       "\n",
       "                           bnpp  cardio_edema  \n",
       "Abachug_50267230_img1     418.0             1  \n",
       "Abadik_50217497_img1     2161.0             1  \n",
       "Abafouck_52403307_img1    118.0             0  \n",
       "Abagash_52691625_img1      49.9             0  \n",
       "Abakleem_50725934_img1  20029.0             1  \n",
       "...                         ...           ...  \n",
       "Zufosloo_50189474_img1   2988.0             1  \n",
       "Zuliquep_52986445_img1   5684.0             1  \n",
       "Zunakot_51932665_img1     123.0             0  \n",
       "Zuplouke_51797661_img1   1290.0             1  \n",
       "Zuridi_50548513_img1     1542.0             1  \n",
       "\n",
       "[16567 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13253 1657 1657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age                                                          78.0\n",
       "bmi                                                         31.22\n",
       "cr                                                           1.77\n",
       "Has_PNA                                                       0.0\n",
       "Has_AcuteHF                                                   1.0\n",
       "images          [[[58, 58, 58, 255], [42, 42, 42, 255], [25, 2...\n",
       "cardio_edema                                                    1\n",
       "Name: Nigomu_52681339_img1, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=list(zip(images, other, bnpp, cardio_edema)), index = ids,columns=['images', 'other','bnpp', 'cardio_edema'])\n",
    "new = df.other.apply(pd.Series) \\\n",
    "    .merge(df, right_index = True, left_index = True) \\\n",
    "    .drop([\"other\"], axis = 1)\n",
    "new.rename(columns={0:'age', 1:'bmi', 2:'cr', 3:'Has_PNA',4:'Has_AcuteHF'},inplace=True)\n",
    "display(new)\n",
    "new.to_csv(WORKING_DIR+'\\\\data\\\\all_data.tsv',sep = '\\t')\n",
    "\n",
    "Y = new['bnpp']\n",
    "new.drop(columns=['bnpp'], inplace=True)\n",
    "X = new\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "print(len(X_train), len(X_test), len(X_val))\n",
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'train.tsv')):\n",
    "    X_train.to_csv(WORKING_DIR+'\\\\data\\\\X_train.tsv', sep='\\t')\n",
    "if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'test.tsv')):\n",
    "    X_test.to_csv(WORKING_DIR+'\\\\data\\\\X_test.tsv', sep='\\t')\n",
    "if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'val.tsv')):\n",
    "    X_val.to_csv(WORKING_DIR+'\\\\data\\\\X_val.tsv', sep='\\t')\n",
    "if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'y_train.tsv')):\n",
    "    y_train.to_csv(WORKING_DIR+'\\\\data\\\\y_train.tsv', sep='\\t')\n",
    "if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'y_test.tsv')):\n",
    "    y_test.to_csv(WORKING_DIR+'\\\\data\\\\y_test.tsv', sep='\\t')\n",
    "if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'y_val.tsv')):\n",
    "    y_val.to_csv(WORKING_DIR+'\\\\data\\\\y_val.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 32.4 GiB for an array with shape (16567, 256, 256, 4) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m f \u001b[39m=\u001b[39m h5py\u001b[39m.\u001b[39mFile(\u001b[39m'\u001b[39m\u001b[39mimages.hdf5\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m f\u001b[39m.\u001b[39;49mcreate_dataset(\u001b[39m'\u001b[39;49m\u001b[39mimages\u001b[39;49m\u001b[39m'\u001b[39;49m, data\u001b[39m=\u001b[39;49mimages)\n\u001b[0;32m      3\u001b[0m f\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Programming-Environments\\Python3-10-8\\lib\\site-packages\\h5py\\_hl\\group.py:161\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    158\u001b[0m         parent_path, name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39mrsplit(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    159\u001b[0m         group \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 161\u001b[0m dsid \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    162\u001b[0m dset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mDataset(dsid)\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mc:\\Programming-Environments\\Python3-10-8\\lib\\site-packages\\h5py\\_hl\\dataset.py:48\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Empty):\n\u001b[0;32m     47\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[1;32m---> 48\u001b[0m     data \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39;49marray_for_new_object(data, specified_dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m     50\u001b[0m \u001b[39m# Validate shape\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Programming-Environments\\Python3-10-8\\lib\\site-packages\\h5py\\_hl\\base.py:118\u001b[0m, in \u001b[0;36marray_for_new_object\u001b[1;34m(data, specified_dtype)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     as_dtype \u001b[39m=\u001b[39m guess_dtype(data)\n\u001b[1;32m--> 118\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(data, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mas_dtype)\n\u001b[0;32m    120\u001b[0m \u001b[39m# In most cases, this does nothing. But if data was already an array,\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39m# and as_dtype is a tagged h5py dtype (e.g. for an object array of strings),\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m# asarray() doesn't replace its dtype object. This gives it the tagged dtype:\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m as_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 32.4 GiB for an array with shape (16567, 256, 256, 4) and data type float64"
     ]
    }
   ],
   "source": [
    "f = h5py.File('images.hdf5','w')\n",
    "f.create_dataset('images', data=images)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "22aa156fa7c00851ea741537c2682c37a12e5d44ca96aed20eea4960f5f5ec6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
